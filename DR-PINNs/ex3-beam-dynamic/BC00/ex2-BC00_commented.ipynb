{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5cd91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Import core libraries and enable future compatibility ===\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "from sympy import integrate, exp, sin, log, oo, pi,symbols\n",
    "import deepxde as dde\n",
    "import scipy.io as scio\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from deepxde.backend import tf\n",
    "#import datetime\n",
    "# import time\n",
    "import os\n",
    "from pylab import mpl\n",
    "from scipy.signal import chirp, spectrogram\n",
    "mpl.rcParams['font.sans-serif']=['Microsoft YaHei']\n",
    "mpl.rcParams['axes.unicode_minus']=False\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "# import xlrd\n",
    "# import xlwt\n",
    "from sympy import *\n",
    "import sympy as sp\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24a629-24f9-44cf-b770-804e6633a64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5abf41-c2e2-4f7d-af82-ab15619caa70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Configure TensorFlow environment flags for JIT and log level ===\n",
    "import os\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices'\n",
    "tf.function(jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee65333-606c-43c2-a0cd-0e3d398567dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === Define function to round numbers to given significant figures ===\n",
    "def round_sf(x, significant_figure=3):\n",
    "    fmt = \"%%.%dg\" % significant_figure\n",
    "    if isinstance(x, np.ndarray):\n",
    "        return np.array([float(fmt % i) for i in x])\n",
    "    else:\n",
    "        return float(fmt % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09f6f18-89f3-4c49-943d-782da5bb8e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read the direct output of the network\n",
    "def Output(X):\n",
    "    Out_final = np.zeros((X.shape[0],7))\n",
    "    import re\n",
    "    lines = open(\"s1.dat\", \"r\").readlines()\n",
    "    S = np.array([np.fromstring(min(re.findall(re.escape(\"[\") + \"(.*?)\" + re.escape(\"]\"), line),\\\n",
    "                                key=len),sep=\",\",) for line in lines ])\n",
    "    dis = S[:,0:num_dis+2][-1]\n",
    "    dis2 = np.array([-0.2,L/2+L_dis/2,1.7])\n",
    "    dis[0] = -0.2\n",
    "    dis[-1] = 1.7\n",
    "    x = X[:,0:1]\n",
    "    index  = [ np.where((x>=dis[i])&(x<dis[i+1]))[0] for i in range(0,dis.shape[0]-1) ]\n",
    "    index2 = [ np.where((x>=dis2[i])&(x<dis2[i+1]))[0] for i in range(0,dis2.shape[0]-1) ]\n",
    "    interv = [ (x>=dis[i])&(x<dis[i+1]) for i in range(0,dis.shape[0]-1) ]\n",
    "    interv2 = [ (x>=dis2[i])&(x<dis2[i+1]) for i in range(0,dis2.shape[0]-1) ]\n",
    "    out_all = model.predict(X)\n",
    "    \n",
    "    u_fai = out_all[:,0:4]\n",
    "    for i in range(2):\n",
    "        Temp = u_fai[:,i::2][interv2[i].ravel()]\n",
    "        Out_final[:,0:2][index2[i]] = Temp\n",
    "                     \n",
    "    Y = out_all[:, 4: 4*num_NN+1]\n",
    "    for i in range(0,num_NN):\n",
    "        Temp = Y[:,i::num_NN][interv[i].ravel()]\n",
    "        Out_final[:,2:-2][index[i]] =  Temp\n",
    "    Out_final[:,-1:] = out_all[:, -1:]\n",
    "    Out_final[:,-2:-1] = out_all[:, -2:-1]\n",
    "    return [Out_final[:,i:i+1] for i in range(0,7)]\n",
    "\n",
    "#Read the output of the derivative function of the network\n",
    "def Output_dNN(X, j = 0):\n",
    "    Y = np.zeros((X.shape[0],1))\n",
    "    import re\n",
    "    lines = open(\"s1.dat\", \"r\").readlines()\n",
    "    S = np.array([np.fromstring(min(re.findall(re.escape(\"[\") + \"(.*?)\" + re.escape(\"]\"), line),\\\n",
    "                                key=len),sep=\",\",) for line in lines ])\n",
    "    dis = S[:,0:num_dis+2][-1]\n",
    "    dis2 = np.array([-0.2,L/2+L_dis/2,1.7])\n",
    "    dis[-1] = dis[-1]+0.001\n",
    "    dis[0] = -0.2\n",
    "    dis[-1] = 1.7\n",
    "    x = X[:,0:1]\n",
    "    index  = [ np.where((x>=dis[i])&(x<dis[i+1]))[0] for i in range(0,dis.shape[0]-1) ]\n",
    "    index2 = [ np.where((x>=dis2[i])&(x<dis2[i+1]))[0] for i in range(0,dis2.shape[0]-1) ]\n",
    "    interv = [ (x>=dis[i])&(x<dis[i+1]) for i in range(0,dis.shape[0]-1) ]\n",
    "    interv2 = [ (x>=dis2[i])&(x<dis2[i+1]) for i in range(0,dis2.shape[0]-1) ]\n",
    "    if j == 0 or j == 1:\n",
    "        for i in range(2):\n",
    "            Temp = model.predict(X[interv2[i].ravel()], operator=lambda x,y:dde.grad.jacobian(y,x, i= j*2+i,j=0))\n",
    "            Y[index2[i]] = Temp\n",
    "    else:\n",
    "        for i in range(0,num_NN):\n",
    "            Temp = model.predict(X[interv[i].ravel()], operator=\\\n",
    "                                                   lambda x,y:dde.grad.jacobian(y,x, i= 4 + (j-2)*num_NN + i,j=0))\n",
    "            Y[index[i]] = Temp\n",
    "    if j == 4 or j ==0:\n",
    "        Y = -Y\n",
    "    return Y\n",
    "\n",
    "#The L2 norm error between the output value directly obtained from the network and the derivative function of the network\n",
    "def Norm_NN(X):\n",
    "    W,fai,dfai,M,V,Dy_t,EI= Output(X)\n",
    "    fai_dNN,dfai_dNN,V_dNN = [Output_dNN(X, j = i) for i in [0,1,3]]\n",
    "\n",
    "    M_dNN = dfai*EI\n",
    "    pre_y1,pre_y2 = Output_label()\n",
    "    EI_exact = NP_EI(X[:,0:1])\n",
    "\n",
    "    norm_fai_dNN = np.linalg.norm(fai-fai_dNN,ord=2) / np.linalg.norm(fai_dNN,ord=2)\n",
    "    norm_dfai_dNN = np.linalg.norm(dfai-dfai_dNN,ord=2) / np.linalg.norm(dfai_dNN,ord=2)\n",
    "    norm_M_dNN = np.linalg.norm(M-M_dNN,ord=2) / np.linalg.norm(M_dNN,ord=2)\n",
    "    norm_V_dNN = np.linalg.norm(V-V_dNN,ord=2) / np.linalg.norm(V_dNN,ord=2)\n",
    "    norm_y1 = np.linalg.norm(ob_y1-pre_y1,ord=2) / np.linalg.norm(ob_y1,ord=2)\n",
    "    norm_y2 = np.linalg.norm(ob_y2-pre_y2,ord=2) / np.linalg.norm(ob_y2,ord=2)\n",
    "    Norm = np.hstack((norm_fai_dNN,norm_dfai_dNN,norm_M_dNN,norm_V_dNN,1,1,norm_y1,norm_y2))\n",
    "    print('norm_fai_dNN,norm_dfai_dNN,norm_M_dNN,norm_V_dNN,--,--,norm_y1,norm_y2')\n",
    "    print(Norm)\n",
    "    return Norm\n",
    "\n",
    "#The predicted value of the point where the output label data is located\n",
    "def Output_label():\n",
    "    pre_y0 = (model.predict(ob_x1)[:,0:1]).reshape(-1,1)\n",
    "    pre_y1 = (model.predict(ob_x2)[:,1:2]).reshape(-1,1)\n",
    "    Pre_y  = np.vstack((pre_y0,pre_y1))\n",
    "    return pre_y0,pre_y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdf2ef-3e0f-428a-8070-9dbbbaee86e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Output_dy_tt(X):\n",
    "    j = 0\n",
    "    dis = np.array([-0.2,L/2+L_dis/2,1.7])\n",
    "    x = X[:,0:1]\n",
    "    interv = [ (x>=dis[i])&(x<dis[i+1]) for i in range(0,dis.shape[0]-1) ]\n",
    "    Out_dNN = model.predict(X[interv[0].ravel()], operator=lambda x,y:dde.grad.hessian(y,x,component=j, i=1,j=1))\n",
    "    for i in range(1,2):\n",
    "        Out_dNN = np.vstack((Out_dNN,model.predict(X[interv[i].ravel()], operator=\\\n",
    "                                               lambda x,y:dde.grad.hessian(y,x,component=j+i, i=1,j=1))))\n",
    "    return Out_dNN\n",
    "\n",
    "def Output_dy_t(X):\n",
    "    j = 0\n",
    "    dis = np.array([-0.2,L/2+L_dis/2,1.7])\n",
    "    x = X[:,0:1]\n",
    "    interv = [ (x>=dis[i])&(x<dis[i+1]) for i in range(0,dis.shape[0]-1) ]\n",
    "    Out_dNN = model.predict(X[interv[0].ravel()], operator=lambda x,y:dde.grad.jacobian(y,x, i=j,j=1))\n",
    "    for i in range(1,2):\n",
    "        Out_dNN = np.vstack((Out_dNN,model.predict(X[interv[i].ravel()], operator=\\\n",
    "                                               lambda x,y:dde.grad.jacobian(y,x, i=j+i, j=1))))\n",
    "    return Out_dNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8c6213-9a43-47ed-a10d-29ff13dfd70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read the true value\n",
    "file_name='beam_dynamic_5HZ_VM_6mm.mat'\n",
    "def Solution(x=0.15,t=-1,name='Dis'):\n",
    "    data = scio.loadmat(file_name)\n",
    "    exact = data[name]\n",
    "    T = data[\"T\"][0][0]\n",
    "    L_Ne = (data[\"L\"]/data[\"Ne\"])[0][0]\n",
    "    dt = data[\"dt\"][0][0]\n",
    "    if t == -1:  # Return the time history of the deflection of the vibration at point x\n",
    "        index = round(x/L_Ne)\n",
    "        T = np.arange(0,T+dt,dt).reshape(-1,1)\n",
    "        X = np.ones_like(T)*x\n",
    "        return np.hstack((X,T,exact[index,:].reshape(-1,1)))\n",
    "    if x == -1: #The vibration mode of the deflection at time t\n",
    "        X = np.arange(0,L+L_Ne,L_Ne).reshape(-1,1)\n",
    "        T =  np.ones_like(X)*t\n",
    "        index = round(t/dt)\n",
    "        return np.hstack((X,T,exact[:,index].reshape(-1,1)))\n",
    "\n",
    "#Set label data\n",
    "def Observe_u(X = [round(0.25 * i,2) for i in range(1,6)], T = -1):\n",
    "    list_reslut = []\n",
    "    if T == -1:\n",
    "        for i in X:\n",
    "            list_reslut.append(Solution(x=i , t=-1)[1:])\n",
    "    if X == -1:\n",
    "        for i in T:\n",
    "            list_reslut.append(Solution(X=-1, t=i)[1:])\n",
    "    return np.array(list_reslut).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3e988-18a3-491f-b6a2-e0a1674d209a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Adaptive sampling method based on residuals\n",
    "def RAR(X,err_total,err,P = 0):\n",
    "    list_pioint_rar = []\n",
    "    for i in range(6):\n",
    "        err_eq = (err_total[i]/err[i])\n",
    "        x_ids = np.argsort(-err_eq,axis=0 )[:20]\n",
    "        points = X[x_ids].reshape(-1,2)\n",
    "        list_pioint_rar.append(points)\n",
    "    if P == 1:\n",
    "        return list_pioint_rar\n",
    "    else:\n",
    "        return np.array(list_pioint_rar).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134b87d9-ec93-4985-833c-1f6f27fa5c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "from matplotlib import rcParams\n",
    " \n",
    "config = {\n",
    "            \"font.family\": 'serif',\n",
    "            \"font.size\": 10.5,\n",
    "            \"mathtext.fontset\": 'stix',\n",
    "            \"font.serif\": ['MicroSoft YaHei'],\n",
    "         }\n",
    "rcParams.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febad3b1-43d7-40d1-b871-e67688d601ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define structural parameters\n",
    "rho = 1180\n",
    "A = 0.05*0.05\n",
    "EI_real = 3e9*0.05*0.05**3/12\n",
    "F = -20*1.5\n",
    "w0 = 5*2*np.pi\n",
    "\n",
    "L = 1.5\n",
    "T = 0.2\n",
    "L_dis = 0.006\n",
    "\n",
    "# === Define segmentation variables (discontinuity points in structure) ===\n",
    "s0 = tf.Variable(-0.01, trainable=False, dtype=tf.float32)\n",
    "s1 = tf.Variable(L/2-L_dis/2, trainable=False, dtype=tf.float32)\n",
    "s2 = tf.Variable(L/2+L_dis/2, trainable=False, dtype=tf.float32)\n",
    "s3 = tf.Variable(L+0.01, trainable=False, dtype=tf.float32)\n",
    "\n",
    "s_mid = tf.Variable(L/2, trainable=False, dtype=tf.float32)\n",
    "\n",
    "SS = [s0,s1,s2,s3]\n",
    "SS_mid = [s0,s_mid,s3]\n",
    "\n",
    "#Set the scaling factor of the network\n",
    "P0 = (tf.Variable(0.01, trainable=True, dtype=tf.float32))\n",
    "P1 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P2 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P3 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P4 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P5 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P6 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P7 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P8 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P9 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "P10 = (tf.Variable(1, trainable=True, dtype=tf.float32))\n",
    "# P11 = (tf.Variable(0.01, trainable=True, dtype=tf.float32))\n",
    "# P12 = (tf.Variable(0.01, trainable=True, dtype=tf.float32))\n",
    "\n",
    "#The coefficients of the adaptive activation function\n",
    "c1 = tf.sigmoid(tf.Variable(0.5, trainable=True, dtype=tf.float32))\n",
    "c2 = tf.sigmoid(tf.Variable(0.5, trainable=True, dtype=tf.float32))\n",
    "c3 = tf.sigmoid(tf.Variable(0.5, trainable=True, dtype=tf.float32))\n",
    "\n",
    "List_P = [P0,P1,P2,P3,P4,P5,P6,P7,P8,P9,P10,c1,c2,c3]\n",
    "\n",
    "num_dis = len(SS)-2\n",
    "num_NN = num_dis+1\n",
    "\n",
    "#Define label data\n",
    "ob_XTY = Observe_u()\n",
    "values = ob_XTY[:, 0:1]\n",
    "bins = [L/2-L_dis/2,L/2+L_dis/2]  \n",
    "indices = np.digitize(values, bins)\n",
    "array1 = ob_XTY[indices.flatten() == 0]\n",
    "array2 = ob_XTY[indices.flatten() == 1]\n",
    "array3 = ob_XTY[indices.flatten() == 2]\n",
    "ob_x1,ob_y1 = array1[:,0:2],array1[:,2:3]\n",
    "ob_x2,ob_y2 = array2[:,0:2],array2[:,2:3]\n",
    "ob_x3,ob_y3 = array3[:,0:2],array3[:,2:3]\n",
    "ob_x1,ob_y1 = Observe_u(X = [round(0.25 * i,2) for i in range(1,4)], T = -1)[:,0:2],\\\n",
    "                Observe_u(X = [round(0.25 * i,2) for i in range(1,4)], T = -1)[:,2:3]\n",
    "# ob_x2,ob_y2 = Observe_u(X = [round(0.25 * i,2) for i in range(2,5)], T = -1)[:,0:2],\\\n",
    "#                 Observe_u(X = [round(0.25 * i,2) for i in range(2,5)], T = -1)[:,2:3]\n",
    "ob_x3,ob_y3 = Observe_u(X = [round(0.25 * i,2) for i in range(4,6)], T = -1)[:,0:2],\\\n",
    "                Observe_u(X = [round(0.25 * i,2) for i in range(4,6)], T = -1)[:,2:3]\n",
    "num_label = 0\n",
    "# observe_u1 = dde.PointSetBC(ob_x1,ob_y1,component=num_NN*num_label)\n",
    "# observe_u2 = dde.PointSetBC(ob_x2,ob_y2,component=num_NN*num_label+1)\n",
    "# observe_u3 = dde.PointSetBC(ob_x3,ob_y3,component=num_NN*num_label+2)\n",
    "\n",
    "observe_u1 = dde.PointSetBC(ob_x1,ob_y1,component=0)\n",
    "observe_u3 = dde.PointSetBC(ob_x3,ob_y3,component=1)\n",
    "\n",
    "XY0 = Solution(x=0.75,t = -1)\n",
    "XY1 = Solution(x=-1,t = 0.05)\n",
    "X1 = XY1[:,0:1]\n",
    "T1 = XY1[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9ac62-8c15-44d7-91c8-c79a98231cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "L/2-L_dis/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e05d48-095d-4d91-8a00-5c54b7968f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Add training anchor points\n",
    "list_x_points = []\n",
    "list_x_points2 = []\n",
    "for i in range(1,9):    \n",
    "    list_x_points.append(np.hstack((X1[::10],X1[::10]*0+0.025*i)))\n",
    "    list_x_points2.append(np.hstack((X1,X1*0+0.025*i)))\n",
    "list_x_points.append(np.hstack((X1[::10],X1[::10]*0+0.01)))\n",
    "list_x_points2.append(np.hstack((X1,X1*0+0.01)))\n",
    "anchors_x0_x = np.vstack([list_x_points[i] for i in range(0,len(list_x_points))])\n",
    "anchors_x0_x0 = np.vstack([list_x_points2[i] for i in range(0,len(list_x_points2))])\n",
    "\n",
    "K = 4\n",
    "np.random.seed(K)\n",
    "tf.set_random_seed(K)\n",
    "anchors_x = np.vstack((np.random.uniform(0,L,8000),np.random.uniform(0,T+0.001,8000))).T\n",
    "anchors_x0 = np.vstack((np.random.uniform(L/2-L_dis/2,L/2+L_dis/2,200),np.random.uniform(0,T+0.001,200))).T\n",
    "anchors_x1 = np.vstack((np.linspace(L/2-L_dis/2,L/2-L_dis/2,800),np.random.uniform(0,T+0.001,800))).T\n",
    "anchors_x2 = np.vstack((np.linspace(L/2+L_dis/2,L/2+L_dis/2,800),np.random.uniform(0,T+0.001,800))).T\n",
    "anchors_x3 = np.vstack((np.linspace(0,0,800),np.random.uniform(0,T+0.001,800))).T\n",
    "anchors_x4 = np.vstack((np.linspace(L,L,800),np.random.uniform(0,T+0.001,800))).T\n",
    "\n",
    "anchors_x = np.vstack((anchors_x,anchors_x0))\n",
    "plt.scatter(anchors_x[:,0:1],anchors_x[:,1:2],s=2)\n",
    "np.savetxt('anchors_x',anchors_x)\n",
    "anchors_x[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16c336-71d6-4193-9583-a50449e010bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hyperparameters and network settings\n",
    "num_domain = 0\n",
    "epochs = 10000\n",
    "lr = 1e-3\n",
    "u_nodenum=20\n",
    "u_layer=2\n",
    "E_nodenum=20\n",
    "E_layer=2\n",
    "activation_func1 = tf.nn.tanh\n",
    "activation_func2 = tf.nn.tanh\n",
    "\n",
    "rho = 1180\n",
    "A = 0.05*0.05\n",
    "EI_real = 3e9*0.05*0.05**3/12\n",
    "F = -20*1.5\n",
    "w0 = 5*2*np.pi\n",
    "\n",
    "#External load function\n",
    "def f(x_in):\n",
    "    cond1 = tf.logical_and(tf.greater_equal(x_in, L/2-L_dis/2), tf.less_equal(x_in, L/2+L_dis/2))\n",
    "    f1 = F/L_dis * tf.ones_like(x_in)\n",
    "    f2 = tf.zeros_like(x_in)\n",
    "    f = tf.where(cond1, f1, f2)\n",
    "    return f\n",
    "\n",
    "def NP_f(x_in,t_in):\n",
    "    cond1 = np.logical_and(np.greater_equal(x_in, L/2-L_dis/2), np.less(x_in, L/2+L_dis/2))\n",
    "    f1 = F/L_dis*np.ones_like(x_in)*np.sin(w0*t_in)\n",
    "    f2 = np.zeros_like(x_in)\n",
    "    f = np.where(cond1, f1, f2)\n",
    "    return f\n",
    "\n",
    "#A function for suppressing the spread of pathological information at the boundaries\n",
    "def f_BC(x_in):\n",
    "    cond1 = tf.logical_and(tf.greater(x_in, 0.05), tf.less(x_in, 1.45))\n",
    "    f1 = tf.ones_like(x_in)\n",
    "    f2 = tf.zeros_like(x_in)\n",
    "    f = tf.where(cond1, f1, f2)\n",
    "    return f\n",
    "\n",
    "def f_T(t_in):\n",
    "    cond1 = tf.logical_and(tf.greater(t_in, 0),tf.less(t_in, 0.01))\n",
    "    f1 = tf.ones_like(t_in)\n",
    "    f2 = tf.zeros_like(t_in)\n",
    "    f = tf.where(cond1, f1, f2)\n",
    "    return f\n",
    "\n",
    "# === Define region-wise indicator function f_sig0(i) ===\n",
    "def f_sig0(x_in,i):\n",
    "    cond1 = tf.logical_and(tf.greater_equal(x_in, SS[i]), tf.less_equal(x_in, SS[i+1]))\n",
    "    f1 = tf.ones_like(x_in)\n",
    "    f2 = tf.zeros_like(x_in)\n",
    "    f = tf.where(cond1, f1, f2)\n",
    "    return f\n",
    "\n",
    "def f_sig_mid(x_in,i):\n",
    "    cond1 = tf.logical_and(tf.greater_equal(x_in, SS_mid[i]), tf.less(x_in, SS_mid[i+1]))\n",
    "    f1 = tf.ones_like(x_in)\n",
    "    f2 = tf.zeros_like(x_in)\n",
    "    f = tf.where(cond1, f1, f2)\n",
    "    return f\n",
    "\n",
    "#Stiffness function\n",
    "def TF_EI(x_in):\n",
    "    f1 = EI_real*(x_in+1)/2\n",
    "    return f1\n",
    "def NP_EI(x_in):\n",
    "    f1 = (0.75+(x_in/L-0.5)**2)\n",
    "    return f1\n",
    "\n",
    "#Set the first-order coupled PDE residual\n",
    "def beampde2(x, y):\n",
    "    x_in = x[:,0:1]\n",
    "    t_in = x[:,1:2]\n",
    "    u     = y[:,0:2]\n",
    "    Fai   = y[:,2:4]\n",
    "    Dfai  = y[:,1+num_NN*1:1+num_NN*2]\n",
    "    M     = y[:,1+num_NN*2:1+num_NN*3]\n",
    "    V     = y[:,1+num_NN*3:1+num_NN*4]\n",
    "    Dy_t  = y[:,1+num_NN*4:2+num_NN*4]\n",
    "    EI    = y[:,2+num_NN*4:3+num_NN*4]\n",
    "    Fai_dNN = []\n",
    "    Dfai_dNN = []\n",
    "    M_dNN = []\n",
    "    V_dNN = []\n",
    "    V2_dNN = []\n",
    "    Q_dNN = []\n",
    "    Dy_t_dNN = []\n",
    "    Dy_tt_dNN = []\n",
    "    \n",
    "    fai_dNN = -dde.grad.jacobian(u, x, i = 0, j=0) * f_sig_mid(x_in,0) -dde.grad.jacobian(u, x, i = 1, j=0) * f_sig_mid(x_in,1)\n",
    "    dfai_dNN = dde.grad.jacobian(Fai, x, i = 0, j=0) * f_sig_mid(x_in,0) + dde.grad.jacobian(Fai, x, i = 1, j=0) * f_sig_mid(x_in,1)\n",
    "    dy_t_dNN = dde.grad.jacobian(u,x, i = 0, j = 1) * f_sig_mid(x_in,0) + dde.grad.jacobian(u,x, i = 1, j = 1) * f_sig_mid(x_in,1)\n",
    "    dy_tt_dNN = dde.grad.hessian(u,x,component=0, i = 1, j = 1) * f_sig_mid(x_in,0)\\\n",
    "                + dde.grad.hessian(u,x,component=1, i = 1, j = 1)* f_sig_mid(x_in,1)\n",
    "    for i in range(num_NN):\n",
    "        m_dNN = EI * Dfai[:,i:i+1]\n",
    "        v_dNN = dde.grad.jacobian(M, x, i = i, j=0)\n",
    "        q_dNN = -dde.grad.jacobian(V, x, i = i, j=0)\n",
    "        M_dNN.append(m_dNN)\n",
    "        V_dNN.append(v_dNN)\n",
    "        Q_dNN.append(q_dNN)\n",
    "        Dy_t_dNN.append(dy_t_dNN)\n",
    "        Dy_tt_dNN.append(dy_tt_dNN)\n",
    "    loss_Fai = 0\n",
    "    loss_Dfai = 0\n",
    "    loss_M = 0\n",
    "    loss_V = 0\n",
    "    loss_Q = 0\n",
    "    loss_EI = 0\n",
    "    loss_Dy_t = 0\n",
    "    loss_Dy_tt = 0\n",
    "    \n",
    "    loss_Fai = (Fai[:,0:1]-fai_dNN) * f_sig_mid(x_in,0) + (Fai[:,1:2]-fai_dNN) * f_sig_mid(x_in,1)    \n",
    "    for i in range(num_NN):\n",
    "        if i == 1:\n",
    "            f_i = F/L_dis\n",
    "            W_i = 0.1\n",
    "        else:\n",
    "            f_i = 0\n",
    "            W_i =1\n",
    "        Weight_M =  tf.sign (tf.tanh(tf.nn.relu( tf.abs(M[:,i:i+1]) - 1e-4)))\n",
    "        loss_Dfai = loss_Dfai + (Dfai[:,i:i+1] - dfai_dNN) * f_sig0(x_in,i)\n",
    "        loss_M = loss_M + (M[:,i:i+1]-M_dNN[i]) * f_sig0(x_in,i)\n",
    "        loss_V = loss_V + (V[:,i:i+1]-V_dNN[i]) * f_sig0(x_in,i)\n",
    "        loss_Dy_t = loss_Dy_t + (Dy_t-Dy_t_dNN[i]) * f_sig0(x_in,i) * f_T(t_in)\n",
    "        loss_Q = loss_Q + ( rho*A*Dy_tt_dNN[i]/EI_real + Q_dNN[i] -f_i*tf.sin(w0*t_in)/EI_real ) * f_sig0(x_in,i)\n",
    "    return [10*loss_Fai,\n",
    "            loss_Dfai,\n",
    "            loss_M,\n",
    "            loss_V,\n",
    "            loss_Dy_t,\n",
    "            loss_Q]\n",
    "\n",
    "\n",
    "def Boun_func1(x,y):\n",
    "    dfai = dde.grad.jacobian(y,x, i =num_NN*1 , j= 0)\n",
    "    return dfai\n",
    "def Boun_func2(x,y):\n",
    "    dfai = dde.grad.jacobian(y,x, i =num_NN*2 -1, j= 0)\n",
    "    return dfai\n",
    "\n",
    "geom = dde.geometry.Interval(0, L)\n",
    "timedomain = dde.geometry.TimeDomain(0, T)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "\n",
    "#Set initial conditions\n",
    "ic1 = dde.icbc.OperatorBC(geomtime,lambda x, y, _: dde.grad.hessian(y, x,component = 0,\\\n",
    "                                                                    i=1,j=1)/EI_real,lambda x, _: np.isclose(x[1], 0))\n",
    "ic2 = dde.icbc.OperatorBC(geomtime,lambda x, y, _: dde.grad.hessian(y, x,component = 1,\\\n",
    "                                                                    i=1,j=1)/EI_real,lambda x, _: np.isclose(x[1], 0))\n",
    "ic3 = dde.icbc.OperatorBC(geomtime,lambda x, y, _: dde.grad.hessian(y, x,component = 2,\\\n",
    "                                                                    i=1,j=1)/EI_real,lambda x, _: np.isclose(x[1], 0))\n",
    "\n",
    "data = dde.data.TimePDE(geomtime,beampde2,[observe_u1,observe_u3],\\\n",
    "                        num_domain=num_domain, anchors=anchors_x)\n",
    "\n",
    "# net = dde.maps.FNN([2] + [100]*3 +  [2+num_NN*4], \"tanh\", \"Glorot uniform\")\n",
    "net = dde.maps.FNN([2] + [2], None, \"Glorot uniform\")\n",
    "\n",
    "#Apply hard constraints for boundary and interface conditions\n",
    "def modify_output(X, y):\n",
    "    x = X[:,0:1]\n",
    "    t = X[:,1:2]\n",
    "    u     = y[:,0:2]\n",
    "    Fai   = y[:,2:4]\n",
    "    Dfai  = y[:,1+num_NN*1:1+num_NN*2]\n",
    "    M     = y[:,1+num_NN*2:1+num_NN*3]\n",
    "    V     = y[:,1+num_NN*3:1+num_NN*4]\n",
    "    Dy_t  = y[:,1+num_NN*4:2+num_NN*4]\n",
    "    \n",
    "    y = c1/(c1+c2+c3)*tf.layers.dense(X, 50, tf.nn.tanh) + c2/(c1+c2+c3)*tf.layers.dense(X, 50, tf.sin)\\\n",
    "         + c3/(c1+c2+c3)*tf.layers.dense(X, 50, tf.nn.elu)\n",
    "    for i in range(4):\n",
    "        y = c1/(c1+c2+c3)*tf.layers.dense(y, 50, tf.nn.tanh) + c2/(c1+c2+c3)*tf.layers.dense(y, 50, tf.sin)\\\n",
    "         + c3/(c1+c2+c3)*tf.layers.dense(y, 50, tf.nn.elu)\n",
    "    y = tf.layers.dense(y, num_NN*5+1, None)\n",
    "    \n",
    "    u     = y[:,0:2]\n",
    "    Fai   = y[:,2:4]\n",
    "    Dfai  = y[:,1+num_NN*1:1+num_NN*2]\n",
    "    M     = y[:,1+num_NN*2:1+num_NN*3]\n",
    "    V     = y[:,1+num_NN*3:1+num_NN*4]\n",
    "    Dy_t  = y[:,1+num_NN*4:2+num_NN*4]\n",
    "    \n",
    "    Hard_BC = tf.layers.dense(t, 30, activation_func2)\n",
    "    for i in range(2):\n",
    "        Hard_BC = tf.layers.dense(Hard_BC, 30, activation_func2)\n",
    "    Hard_BC = tf.layers.dense(Hard_BC, 8, None)\n",
    "    \n",
    "    EI = tf.layers.dense(x, E_nodenum, activation_func2)\n",
    "    for i in range(2):\n",
    "        EI = tf.layers.dense(EI, E_nodenum, activation_func2)\n",
    "    EI = tf.layers.dense(EI, 1, None)\n",
    "\n",
    "    \n",
    "    final_output = tf.concat([0.01*t*(x*u[:,0:1]*(x-s_mid) + P1*Hard_BC[:,0:1]*x/s_mid),\\\n",
    "                              0.01*t*(u[:,1:2]*(x-L)*(x-s_mid) + P1*Hard_BC[:,0:1]*(x-L)/(s_mid-L)),\\\n",
    "                              0.01*t*(Fai[:,0:1]*(x-s_mid) + P2*Hard_BC[:,1:2]), \\\n",
    "                              0.01*t*(Fai[:,1:2]*(x-s_mid) + P2*Hard_BC[:,1:2]), \\\n",
    "                              0.01*t*(x*Dfai[:,0:1]*(x-s1)+P3*Hard_BC[:,2:3]*x/s1),\\\n",
    "                              0.01*t*(Dfai[:,1:2]*(x-s1)*(x-s2)+P3*Hard_BC[:,2:3]*(x-s2)/(s1-s2)+\\\n",
    "                                                                P4*Hard_BC[:,3:4]*(x-s1)/(s2-s1)),\\\n",
    "                              0.01*t*(Dfai[:,2:3]*(x-L)*(x-s2)+P4*Hard_BC[:,3:4]*(x-L)/(s2-L)),\\\n",
    "                              0.01*t*(x*M[:,0:1]*(x-s1)+P5*Hard_BC[:,4:5]*x/s1),\\\n",
    "                              0.01*t*(M[:,1:2]*(x-s1)*(x-s2)+P5*Hard_BC[:,4:5]*(x-s2)/(s1-s2)+P6*Hard_BC[:,5:6]*(x-s1)/(s2-s1)),\\\n",
    "                              0.01*t*(M[:,2:3]*(x-L)*(x-s2)+P6*Hard_BC[:,5:6]*(x-L)/(s2-L)),\\\n",
    "                              0.01*t*(V[:,0:1]*(x-s1)+P7*Hard_BC[:,6:7]),\\\n",
    "                              0.01*t*(V[:,1:2]*(x-s1)*(x-s2)+P7*Hard_BC[:,6:7]*(x-s2)/(s1-s2)+P8*Hard_BC[:,7:8]*(x-s1)/(s2-s1)),\\\n",
    "                              0.01*t*(V[:,2:3]*(x-s2)+P8*Hard_BC[:,7:8]),\\\n",
    "                              P0*t*(x*Dy_t*(x-L)),\n",
    "                              tf.abs(EI)\n",
    "                             ], axis=1)\n",
    "    return final_output\n",
    "\n",
    "net.apply_output_transform(modify_output)\n",
    "variable = dde.callbacks.VariableValue(SS, period=200, filename=\"s1.dat\")#200为epochs之间的间隔\n",
    "variable2 = dde.callbacks.VariableValue(List_P, period=200, filename=\"w1.dat\")#200为epochs之间的间隔\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "Num_loss = 8\n",
    "\n",
    "loss = []\n",
    "Weight = np.ones(Num_loss)\n",
    "Weight[-2:] = 100\n",
    "for i in range(Num_loss):\n",
    "    loss.append('MAE')\n",
    "    # if i <13:\n",
    "    #     if i%2==1:\n",
    "    #         loss[i] = 'MSE'\n",
    "print(loss)\n",
    "#     if 1<i<6:\n",
    "#         loss[i] = 'zero'\n",
    "# loss[4] = 'MAE'\n",
    "total_time = 0\n",
    "start_time = time.time()\n",
    "model.compile(\"adam\", lr, loss_weights=list(Weight.ravel()), loss = loss)\n",
    "losshistory, train_state = model.train(epochs=20000, callbacks=[variable,variable2])\n",
    "end_time = time.time()\n",
    "total_time = total_time + end_time - start_time\n",
    "list_NN = []\n",
    "list_points = []\n",
    "list_reslut = []\n",
    "\n",
    "NN = Output(XY1[:,0:2])\n",
    "NN = np.array(NN).reshape(len(NN),-1).T\n",
    "EI = NN[:,-1:]\n",
    "norm_EI = np.linalg.norm((EI-NP_EI(X1)),ord=2) / np.linalg.norm(NP_EI(X1),ord=2)\n",
    "list_NN.append(np.array(NN).reshape(len(NN),-1).T)\n",
    "list_reslut.append(norm_EI)\n",
    "print('Norm_EI',norm_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530f753-1920-48dc-8c0b-a43133cfe20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reduce the learning rate\n",
    "model.compile(\"adam\", 1e-4, loss_weights=list(Weight.ravel()), loss = loss)\n",
    "losshistory, train_state = model.train(epochs=20000, callbacks=[variable,variable2])\n",
    "NN = Output(XY1[:,0:2])\n",
    "NN = np.array(NN).reshape(len(NN),-1).T\n",
    "EI = NN[:,-1:]\n",
    "norm_EI = np.linalg.norm((EI-NP_EI(X1)),ord=2) / np.linalg.norm(NP_EI(X1),ord=2)\n",
    "list_NN.append(np.array(NN).reshape(len(NN),-1).T)\n",
    "list_reslut.append(norm_EI)\n",
    "print('Norm_EI',norm_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029fd348-8b03-46f7-af7b-f74dc30a6f20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # model.compile(\"adam\", 1e-4, loss_weights=list(Weight.ravel()), loss = loss)\n",
    "    losshistory, train_state = model.train(epochs=20000, callbacks=[variable,variable2])\n",
    "    NN = Output(XY1[:,0:2])\n",
    "    NN = np.array(NN).reshape(len(NN),-1).T\n",
    "    EI = NN[:,-1:]\n",
    "    norm_EI = np.linalg.norm((EI-NP_EI(X1)),ord=2) / np.linalg.norm(NP_EI(X1),ord=2)\n",
    "    list_NN.append(np.array(NN).reshape(len(NN),-1).T)\n",
    "    list_reslut.append(norm_EI)\n",
    "    print('Norm_EI',norm_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae08643-292e-4028-8b41-8482a50c7323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(13):\n",
    "    # model.compile(\"adam\", 1e-4, loss_weights=list(Weight.ravel()), loss = loss)\n",
    "    losshistory, train_state = model.train(epochs=20000, callbacks=[variable,variable2])\n",
    "    NN = Output(XY1[:,0:2])\n",
    "    NN = np.array(NN).reshape(len(NN),-1).T\n",
    "    EI = NN[:,-1:]\n",
    "    norm_EI = np.linalg.norm((EI-NP_EI(X1)),ord=2) / np.linalg.norm(NP_EI(X1),ord=2)\n",
    "    list_NN.append(np.array(NN).reshape(len(NN),-1).T)\n",
    "    list_reslut.append(norm_EI)\n",
    "    print('Norm_EI',norm_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ba260-0656-4b34-a261-e6a4f039ef1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "losshistory, train_state = model.train(epochs=23106, callbacks=[variable,variable2])\n",
    "NN = Output(XY1[:,0:2])\n",
    "NN = np.array(NN).reshape(len(NN),-1).T\n",
    "EI = NN[:,-1:]\n",
    "norm_EI = np.linalg.norm((EI-NP_EI(X1)),ord=2) / np.linalg.norm(NP_EI(X1),ord=2)\n",
    "list_NN.append(np.array(NN).reshape(len(NN),-1).T)\n",
    "list_reslut.append(norm_EI)\n",
    "print('Norm_EI',norm_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac31edd-c2d5-4bdc-932b-5262513ae041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:TensorFlow]",
   "language": "python",
   "name": "conda-env-TensorFlow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
